{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1713ae431830f571",
   "metadata": {},
   "source": [
    "### Tracking Trending Games\n",
    "\n",
    "This notebook provides a way to get and save the top 100 games in a set category corresponding to Steam's categories, namely “New & Trending”, “Top Sellers”, “Global Top Sellers”, “Popular Upcoming” and “Specials”. These categories directly correspond to tabs on Steam's store page and can be accessed via the following API: https://store.steampowered.com/search/results\n",
    "\n",
    "The API has several parameters which correspond to tags on Steam to limit searches, such as 'Show Free to Play', 'Tags', 'Categories', etc.\n",
    "\n",
    "Run this notebook each time you would like to update these categories for use in the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d8b64b-bf15-43ca-a5d3-576b561f2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Helper functions\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import requests\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "def print_log(*args):\n",
    "    print(f\"[{str(datetime.now())[:-3]}] \", end=\"\")\n",
    "    print(*args)\n",
    "    \n",
    "def get_search_results(params):\n",
    "    req_sr = requests.get(\n",
    "        \"https://store.steampowered.com/search/results/\",\n",
    "        params=params)\n",
    "    \n",
    "    if req_sr.status_code != 200:\n",
    "        print_log(f\"Failed to get search results: {req_sr.status_code}\")\n",
    "        return {\"items\": []}\n",
    "    \n",
    "    try:\n",
    "        search_results = req_sr.json()\n",
    "    except Exception as e:\n",
    "        print_log(f\"Failed to parse search results: {e}\")\n",
    "        return {\"items\": []}\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "def get_app_details(appid, logo_url=None):\n",
    "    def is_bundle_url(url):\n",
    "        return url and \"steam/bundles/\" in url\n",
    "\n",
    "    if appid is None:\n",
    "        print_log(\"App ID is None.\")\n",
    "        return {\"success\": False, \"data\": {}}\n",
    "\n",
    "    is_bundle_app = is_bundle_url(logo_url)\n",
    "\n",
    "    url = (\n",
    "        \"https://store.steampowered.com/actions/ajaxresolvebundles\"\n",
    "        if is_bundle_app else\n",
    "        \"https://store.steampowered.com/api/appdetails/\"\n",
    "    )\n",
    "\n",
    "    params = (\n",
    "        {\"bundleids\": appid, \"cc\": \"US\", \"l\": \"english\"}\n",
    "        if is_bundle_app else\n",
    "        {\"appids\": appid, \"cc\": \"us\", \"l\": \"english\"}\n",
    "    )\n",
    "\n",
    "    log_type = \"bundle\" if is_bundle_app else \"app\"\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            resp = requests.get(url, params=params)\n",
    "        except Exception as e:\n",
    "            print_log(f\"Request failed for {log_type} {appid}: {e}\")\n",
    "            return {\"success\": False, \"data\": {}}\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            try:\n",
    "                json_data = resp.json()\n",
    "                key = str(appid)\n",
    "                result_data = json_data.get(key, {})\n",
    "                print_log(f\"{log_type.capitalize()} ID {appid} - Success: {result_data.get('success', True)}\")\n",
    "                return {\"success\": True, \"data\": result_data}\n",
    "            except Exception as e:\n",
    "                print_log(f\"Failed to parse {log_type} JSON for ID {appid}: {e}\")\n",
    "                return {\"success\": False, \"data\": {}}\n",
    "        elif resp.status_code == 429:\n",
    "            print_log(f\"429 Too Many Requests for {log_type} {appid}. Sleeping 10s.\")\n",
    "            time.sleep(10)\n",
    "        elif resp.status_code == 403:\n",
    "            print_log(f\"403 Forbidden for {log_type} {appid}. Sleeping 5m.\")\n",
    "            time.sleep(300)\n",
    "        else:\n",
    "            print_log(f\"Error {resp.status_code} while retrieving {log_type} {appid}\")\n",
    "            return {\"success\": False, \"data\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b757efdc-7504-4855-a477-758a1b3573ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-16 08:17:20.910] Checkpoint folder: C:\\Users\\azure\\Documents\\CS122\\project\\checkpoints\n",
      "[2025-05-16 08:17:20.923] Successfully load apps_dict checkpoint: C:\\Users\\azure\\Documents\\CS122\\project\\checkpoints\\apps_dict-ckpt-fin.p\n",
      "[2025-05-16 08:17:20.923] Number of apps in apps_dict: 500\n",
      "[2025-05-16 08:17:20.923] Successfully load excluded_apps_list checkpoint: C:\\Users\\azure\\Documents\\CS122\\project\\checkpoints\\excluded_apps_list-ckpt-fin.p\n",
      "[2025-05-16 08:17:20.923] Number of apps in excluded_apps_list: 187\n",
      "[2025-05-16 08:17:20.923] Successfully load error_apps_list checkpoint: C:\\Users\\azure\\Documents\\CS122\\project\\checkpoints\\error_apps_list-ckpt-fin.p\n",
      "[2025-05-16 08:17:20.923] Number of apps in error_apps_list: 0\n"
     ]
    }
   ],
   "source": [
    "# Code to add games not already present in checkpoint folder\n",
    "\n",
    "def print_log(*args):\n",
    "    print(f\"[{str(datetime.now())[:-3]}] \", end=\"\")\n",
    "    print(*args)\n",
    "\n",
    "def save_checkpoints(checkpoint_folder, apps_dict_filename_prefix, exc_apps_filename_prefix, error_apps_filename_prefix, apps_dict, excluded_apps_list, error_apps_list):\n",
    "    if not checkpoint_folder.exists():\n",
    "        checkpoint_folder.mkdir(parents=True)\n",
    "\n",
    "    save_path = checkpoint_folder.joinpath(\n",
    "        apps_dict_filename_prefix + f'-ckpt-fin.p'\n",
    "    ).resolve()\n",
    "\n",
    "    save_path2 = checkpoint_folder.joinpath(\n",
    "        exc_apps_filename_prefix + f'-ckpt-fin.p'\n",
    "    ).resolve()\n",
    "    \n",
    "    save_path3 = checkpoint_folder.joinpath(\n",
    "        error_apps_filename_prefix + f'-ckpt-fin.p'\n",
    "    ).resolve()\n",
    "\n",
    "    save_pickle(save_path, apps_dict)\n",
    "    print_log(f'Successfully create app_dict checkpoint: {save_path}')\n",
    "\n",
    "    save_pickle(save_path2, excluded_apps_list)\n",
    "    print_log(f\"Successfully create excluded apps checkpoint: {save_path2}\")\n",
    "\n",
    "    save_pickle(save_path3, error_apps_list)\n",
    "    print_log(f\"Successfully create error apps checkpoint: {save_path3}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "def load_pickle(path_to_load:Path) -> dict:\n",
    "    obj = pickle.load(open(path_to_load, \"rb\"))\n",
    "    \n",
    "    return obj\n",
    "\n",
    "def save_pickle(path_to_save:Path, obj):\n",
    "    with open(path_to_save, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def check_latest_checkpoints(checkpoint_folder, apps_dict_filename_prefix, exc_apps_filename_prefix, error_apps_filename_prefix):\n",
    "    # app_dict\n",
    "    all_pkl = []\n",
    "\n",
    "    # get all pickle files in the checkpoint folder    \n",
    "    for root, dirs, files in os.walk(checkpoint_folder):\n",
    "        all_pkl = list(map(lambda f: Path(root, f), files))\n",
    "        all_pkl = [p for p in all_pkl if p.suffix == '.p']\n",
    "        break\n",
    "            \n",
    "    # create a list to store all the checkpoint files\n",
    "    # then sort them\n",
    "    # the latest checkpoint file for each of the object is the last element in each of the lists\n",
    "    apps_dict_ckpt_files = [f for f in all_pkl if apps_dict_filename_prefix in f.name and \"ckpt\" in f.name]\n",
    "    exc_apps_list_ckpt_files = [f for f in all_pkl if exc_apps_filename_prefix in f.name and \"ckpt\" in f.name]\n",
    "    error_apps_ckpt_files = [f for f in all_pkl if error_apps_filename_prefix in f.name and 'ckpt' in f.name]\n",
    "\n",
    "    apps_dict_ckpt_files.sort()\n",
    "    exc_apps_list_ckpt_files.sort()\n",
    "    error_apps_ckpt_files.sort()\n",
    "\n",
    "    latest_apps_dict_ckpt_path = apps_dict_ckpt_files[-1] if apps_dict_ckpt_files else None\n",
    "    latest_exc_apps_list_ckpt_path = exc_apps_list_ckpt_files[-1] if exc_apps_list_ckpt_files else None\n",
    "    latest_error_apps_list_ckpt_path = error_apps_ckpt_files[-1] if error_apps_ckpt_files else None\n",
    "\n",
    "    return latest_apps_dict_ckpt_path, latest_exc_apps_list_ckpt_path, latest_error_apps_list_ckpt_path\n",
    "\n",
    "apps_dict_filename_prefix = 'apps_dict'\n",
    "exc_apps_filename_prefix = 'excluded_apps_list'\n",
    "error_apps_filename_prefix = 'error_apps_list'\n",
    "\n",
    "apps_dict = {}\n",
    "excluded_apps_list = []\n",
    "error_apps_list = []\n",
    "\n",
    "# path = project directory (i.e. steam_data_scraping)/checkpoints\n",
    "checkpoint_folder = Path('../checkpoints').resolve()\n",
    "\n",
    "print_log('Checkpoint folder:', checkpoint_folder)\n",
    "\n",
    "if not checkpoint_folder.exists():\n",
    "    print_log(f'Fail to find checkpoint folder: {checkpoint_folder}')\n",
    "    print_log(f'Start at blank.')\n",
    "\n",
    "    checkpoint_folder.mkdir(parents=True)\n",
    "\n",
    "latest_apps_dict_ckpt_path, latest_exc_apps_list_ckpt_path, latest_error_apps_list_ckpt_path = check_latest_checkpoints(checkpoint_folder, apps_dict_filename_prefix, exc_apps_filename_prefix, error_apps_filename_prefix)\n",
    "\n",
    "if latest_apps_dict_ckpt_path:\n",
    "    apps_dict = load_pickle(latest_apps_dict_ckpt_path)\n",
    "    print_log('Successfully load apps_dict checkpoint:', latest_apps_dict_ckpt_path)\n",
    "    print_log(f'Number of apps in apps_dict: {len(apps_dict)}')\n",
    "\n",
    "if latest_exc_apps_list_ckpt_path:\n",
    "    excluded_apps_list = load_pickle(latest_exc_apps_list_ckpt_path)\n",
    "    print_log(\"Successfully load excluded_apps_list checkpoint:\", latest_exc_apps_list_ckpt_path)\n",
    "    print_log(f'Number of apps in excluded_apps_list: {len(excluded_apps_list)}')\n",
    "\n",
    "if latest_error_apps_list_ckpt_path:\n",
    "    error_apps_list = load_pickle(latest_error_apps_list_ckpt_path)\n",
    "    print_log(\"Successfully load error_apps_list checkpoint:\", latest_error_apps_list_ckpt_path)\n",
    "    print_log(f'Number of apps in error_apps_list: {len(error_apps_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d1b393-6a93-47f1-a16d-d771950d40cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-16 08:17:20.941] File topsellers_20250516.pkl exists. Skip.\n",
      "[2025-05-16 08:17:20.941] File globaltopsellers_20250516.pkl exists. Skip.\n",
      "[2025-05-16 08:17:20.941] File popularnew_20250516.pkl exists. Skip.\n",
      "[2025-05-16 08:17:20.941] File popularcommingsoon_20250516.pkl exists. Skip.\n",
      "[2025-05-16 08:17:20.941] File specials_20250516.pkl exists. Skip.\n"
     ]
    }
   ],
   "source": [
    "# Main code\n",
    "\n",
    "execute_datetime = datetime.now()\n",
    "\n",
    "search_result_folder_path = Path(f\"../checkpoints/searchresults/search_results_{execute_datetime.strftime('%Y%m%d')}\")\n",
    "if not search_result_folder_path.exists():\n",
    "    search_result_folder_path.mkdir()\n",
    "    \n",
    "# a list of filters\n",
    "params_list = [\n",
    "    {\"filter\": \"topsellers\"},\n",
    "    {\"filter\": \"globaltopsellers\"},\n",
    "    {\"filter\": \"popularnew\"},\n",
    "    {\"filter\": \"popularcommingsoon\"},\n",
    "    {\"filter\": \"\", \"specials\": 1}\n",
    "]\n",
    "page_list = list(range(1, 5))\n",
    "\n",
    "params_sr_default = {\n",
    "    \"filter\": \"topsellers\",\n",
    "    \"hidef2p\": 1,\n",
    "    \"page\": 1,            # page is used to go through different parts of the ranking. Each page contains 25 results\n",
    "    \"json\": 1\n",
    "}\n",
    "\n",
    "for update_param in params_list:\n",
    "\n",
    "    items_all = []\n",
    "    if update_param[\"filter\"]:\n",
    "        filename = f\"{update_param['filter']}_{execute_datetime.strftime('%Y%m%d')}.pkl\"\n",
    "    else:\n",
    "        filename = f\"specials_{execute_datetime.strftime('%Y%m%d')}.pkl\"\n",
    "\n",
    "    if (search_result_folder_path / filename).exists():\n",
    "        print_log(f\"File {filename} exists. Skip.\")\n",
    "        continue\n",
    "\n",
    "    for page_no in page_list:\n",
    "        param = params_sr_default.copy()\n",
    "        param.update(update_param)\n",
    "        param[\"page\"] = page_no\n",
    "\n",
    "        search_results = get_search_results(param)\n",
    "        print_log(search_results)\n",
    "\n",
    "        if not search_results:\n",
    "            continue\n",
    "\n",
    "        items = search_results.get(\"items\", [])\n",
    "\n",
    "        # proprocessing search results to retrieve the appid of the game\n",
    "        for item in items:\n",
    "            try:\n",
    "                item[\"appid\"] = re.search(r\"steam/\\w+/(\\d+)\", item[\"logo\"]).group(1)      # the URL can be steam/bundles/{appid} or steam/apps/{appid}\n",
    "            except Exception as e:\n",
    "                print_log(f\"Failed to extract appid: {e}\")\n",
    "                item[\"appid\"] = None\n",
    "\n",
    "        # request for game information using appid\n",
    "        for item in items:\n",
    "            appid = item[\"appid\"]\n",
    "            if not appid:\n",
    "                continue\n",
    "        \n",
    "            appid = int(appid)  # Ensure it's an int\n",
    "            logo_url = item.get(\"logo\")\n",
    "        \n",
    "            try:\n",
    "                appdetails = get_app_details(appid, logo_url)\n",
    "            except Exception as e:\n",
    "                print_log(f\"Error retrieving details for app ID {appid}: {e}\")\n",
    "                item[\"appdetail\"] = {\"success\": False}\n",
    "                if appid not in error_apps_list:\n",
    "                    error_apps_list.append(appid)\n",
    "                continue\n",
    "        \n",
    "            item[\"appdetail\"] = appdetails\n",
    "        \n",
    "            # Add to apps_dict only if successful and not already present\n",
    "            if appdetails.get(\"success\") and appid not in apps_dict:\n",
    "                appdetails_data = appdetails['data']\n",
    "\n",
    "                appdetails_data['appid'] = appid     \n",
    "\n",
    "                apps_dict[appid] = appdetails_data\n",
    "                print_log(f\"Successfully get content of App ID: {appid}\")\n",
    "        \n",
    "            elif not appdetails.get(\"success\"):\n",
    "                if appid not in excluded_apps_list:\n",
    "                    excluded_apps_list.append(appid)\n",
    "                    print_log(f\"App ID {appid} not successful. Added to excluded_apps_list.\")\n",
    "\n",
    "\n",
    "        items_all.extend(items)\n",
    "\n",
    "    # save the search results\n",
    "    with open(search_result_folder_path / filename, \"wb\") as f:\n",
    "        pickle.dump(items_all, f)\n",
    "    print_log(f\"Saved {filename}\")\n",
    "\n",
    "    save_checkpoints(checkpoint_folder,apps_dict_filename_prefix,exc_apps_filename_prefix,error_apps_filename_prefix,apps_dict,excluded_apps_list,error_apps_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb4a80a-c077-4f33-ae3b-f4e282971fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-16 08:17:20.953] Flattened 0 incorrectly structured app entries in apps_dict.\n",
      "[2025-05-16 08:17:20.954] Successfully create app_dict checkpoint: C:\\Users\\azure\\Documents\\CS122\\project\\checkpoints\\apps_dict-ckpt-fin.p\n",
      "[2025-05-16 08:17:20.954] Successfully create excluded apps checkpoint: C:\\Users\\azure\\Documents\\CS122\\project\\checkpoints\\excluded_apps_list-ckpt-fin.p\n",
      "[2025-05-16 08:17:20.955] Successfully create error apps checkpoint: C:\\Users\\azure\\Documents\\CS122\\project\\checkpoints\\error_apps_list-ckpt-fin.p\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# --- RETROACTIVE FIX: Flatten any wrapped appdetails entries ---\n",
    "fixed_count = 0\n",
    "new_apps_dict = {} \n",
    "\n",
    "for item in items_all:\n",
    "    appid = item.get(\"appid\")\n",
    "    if not appid:\n",
    "        continue\n",
    "    appid = int(appid)\n",
    "\n",
    "    existing = apps_dict.get(appid)\n",
    "\n",
    "    # Check for wrapped format\n",
    "    if isinstance(existing, dict) and \"success\" in existing and \"data\" in existing:\n",
    "        if existing[\"success\"] and isinstance(existing[\"data\"], dict):\n",
    "            new_apps_dict[appid] = existing[\"data\"]\n",
    "            new_apps_dict[appid][\"appid\"] = appid  # Optional, add if not present\n",
    "            fixed_count += 1\n",
    "        else:\n",
    "            # If 'success' is False or 'data' is not a dict, keep the original\n",
    "            new_apps_dict[appid] = existing\n",
    "    else:\n",
    "        # If not in the wrapped format, keep the original\n",
    "        new_apps_dict[appid] = existing\n",
    "\n",
    "print_log(f\"Flattened {fixed_count} incorrectly structured app entries in apps_dict.\")\n",
    "\n",
    "# Resave updated checkpoint with the new dictionary\n",
    "save_checkpoints(\n",
    "    checkpoint_folder,\n",
    "    apps_dict_filename_prefix,\n",
    "    exc_apps_filename_prefix,\n",
    "    error_apps_filename_prefix,\n",
    "    new_apps_dict,\n",
    "    excluded_apps_list,\n",
    "    error_apps_list\n",
    ")\n",
    "\n",
    "print(new_apps_dict.get(2277560))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3825d7-4456-4cf4-8f58-cc108d706a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
